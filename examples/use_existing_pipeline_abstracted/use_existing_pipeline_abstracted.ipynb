{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstraction: How to auto-map data with 2 lines of code\n",
    "\n",
    "This cookbook builds upon the foundation of the `Use Existing Pipeline` cookbook, linked [here](https://github.com/Lume-ai/lume-cookbooks/tree/main/examples/use_existing_pipeline). This contains the same functionality, but provides abstracted functions to make it a few-line integration. \n",
    "\n",
    "‚ùì See a video walkthrough of this notebook [here](https://www.loom.com/share/63a42b2f4b6d4439a45e461ea543033c)\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook contains the following 1 section:\n",
    "\n",
    "- **Map incoming source data using an existing pipeline:** Specify a set of functions and use the Lume API to map data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map incoming source data using an existing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your API key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '<YOUR_API_KEY>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "\n",
    "First let's define a few utilities for making calls to the Lume API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx \n",
    "import traceback\n",
    "import asyncio\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "url = \"https://api.lume.ai/crud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_pipeline(pipeline_id):\n",
    "    new_url = f'{url}/pipelines/{pipeline_id}'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    async with httpx.AsyncClient(timeout=60) as client:\n",
    "        job = await client.get(new_url, headers=headers)\n",
    "        job = job.json()\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_job(pipeline_id, data):\n",
    "    new_url = f'{url}/pipelines/{pipeline_id}/jobs'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    payload = {\n",
    "        \"data\": data\n",
    "    }\n",
    "    async with httpx.AsyncClient(timeout=60) as client:\n",
    "        job = await client.post(new_url, headers=headers, json=payload)\n",
    "        job = job.json()\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_job(job_id):\n",
    "    new_url = f'{url}/jobs/{job_id}/run'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    payload = {\n",
    "        \"immediate_return\": True # required to set this to True for polling.\n",
    "    }\n",
    "    async with httpx.AsyncClient(timeout=6000) as client:\n",
    "        job = await client.post(new_url, headers=headers, json=payload)\n",
    "        job = job.json()\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_result(result_id):\n",
    "    new_url = f'{url}/results/{result_id}'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    async with httpx.AsyncClient(timeout=60) as client:\n",
    "        job = await client.get(new_url, headers=headers)\n",
    "        job = job.json()\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def poll_result(result_id, interval=3):\n",
    "    while True:\n",
    "        result = await get_result(result_id)\n",
    "        if result['status'] != 'running' and result['status'] != 'queued':\n",
    "            return result\n",
    "        await asyncio.sleep(interval)  # Wait for the specified interval before polling again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_mappings_from_result(result_id, page=1, size=50):\n",
    "    new_url = f'{url}/results/{result_id}/mappings'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    params = {\n",
    "        'page': page, \n",
    "        'size': size  # Number of records per page\n",
    "    }\n",
    "    async with httpx.AsyncClient(timeout=60) as client:\n",
    "        job = await client.get(new_url, headers=headers, params=params)\n",
    "        job = job.json()\n",
    "    return job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search(model, params):\n",
    "    new_url = f'{url}/search'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"params\": params\n",
    "    }\n",
    "    async with httpx.AsyncClient(timeout=6000) as client:\n",
    "        retPage = await client.post(new_url, headers=headers, json=payload)\n",
    "        retPage = retPage.json()\n",
    "    return retPage['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_pipeline_with_name(pipeline_name):\n",
    "    pipelines = await search('pipeline', {'name': pipeline_name})\n",
    "    if len(pipelines) < 1:\n",
    "        raise ValueError(f\"Pipeline with name {pipeline_name} not found\")\n",
    "    pipeline = pipelines[0]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_all_mappings(result_id):\n",
    "    mappings = []\n",
    "    first_page = await get_mappings_from_result(result_id)\n",
    "    mappings.extend(first_page['items'])\n",
    "\n",
    "    total_items = first_page['total']\n",
    "    page_size = first_page['size']\n",
    "    total_pages = total_items // page_size + 1\n",
    "\n",
    "    for page in range(2, total_pages + 1):\n",
    "        new_mappings_page = await get_mappings_from_result(result_id, page=page)\n",
    "        mappings.extend(new_mappings_page['items'])\n",
    "    return mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def executeJobTransformation(pipeline_name, data):\n",
    "    print(\"Fetching pipeline\")\n",
    "    pipeline = await get_pipeline_with_name(pipeline_name)\n",
    "    if pipeline is None:\n",
    "        raise ValueError(f\"Pipeline with name {pipeline_name} not found\")\n",
    "    job = await create_job(pipeline['id'], data)\n",
    "    print(\"created job\")\n",
    "    initial_result = await run_job(job['id'])\n",
    "    print(\"dispatched job\")\n",
    "    result = await poll_result(initial_result['id'])\n",
    "    all_mappings = await get_all_mappings(result['id'])\n",
    "    return all_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Context\n",
    "\n",
    "`Target Schema`: This cookbook assumes a pipeline has already been created, called `ecommerce_demo`. The existing pipeline is built to map source ecommerce data to an internal ecommerce data model. The target schema used in the pipeline is in this cookbook's folder, as `target_schema.json`. You can view it in detail there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Let's access our source data and use a Lume pipeline to map it automatically.\n",
    "\n",
    "The source data is in this cookbook's folder, as `source_data.json`. The cell below loads the source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_path = os.path.join(os.getcwd(), 'source_data.json')\n",
    "with open(source_data_path) as f:\n",
    "    source_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use Lume to map this source data automatically, using an existing pipeline. Use the abstracted `executeJobTransformation` function to do so in 2 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Map data with 2 lines of code\n",
    "Use the abstracted `executeJobTransformation` function to map data. Depending on where your source data arrived (system x, api y, etc), use that knowledge to fetch the corresponding pipeline via the pipeline name, `ecommerce_demo` in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'ecommerce_demo'\n",
    "all_mappings = await executeJobTransformation(pipeline_name, source_data)\n",
    "all_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Pipe the output to your end destination\n",
    "After getting the final mapped data, send it to the next step of your workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
