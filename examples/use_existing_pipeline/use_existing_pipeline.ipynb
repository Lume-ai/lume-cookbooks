{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lume: How to auto-map data in your code\n",
    "\n",
    "After running a job to create a mapper, you can use it as an embedded pipeline in your code. This is especially helpful to create pipelines where similar data will come in, and you need to embed a static mapper after creating it with Lume.\n",
    "\n",
    "‚ùì See a video walkthrough of this notebook [here](https://www.loom.com/share/63a42b2f4b6d4439a45e461ea543033c)\n",
    "### Overview\n",
    "\n",
    "This notebook contains the following 1 section:\n",
    "\n",
    "- **Map incoming source data using an existing pipeline:** Specify a set of functions and use the Lume API to map data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map incoming source data using an existing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your API key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '<YOUR_API_KEY>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "\n",
    "First let's define a few utilities for making calls to the Lume API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx \n",
    "import traceback\n",
    "import asyncio\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "url = \"https://api.lume.ai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_pipeline(pipeline_id):\n",
    "    new_url = f'{url}/pipelines/{pipeline_id}'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    async with httpx.AsyncClient(timeout=60) as client:\n",
    "        job = await client.get(new_url, headers=headers)\n",
    "        job = job.json()\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_job(pipeline_id, data):\n",
    "    new_url = f'{url}/pipelines/{pipeline_id}/jobs'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    payload = {\n",
    "        \"data\": data\n",
    "    }\n",
    "    async with httpx.AsyncClient(timeout=60) as client:\n",
    "        job = await client.post(new_url, headers=headers, json=payload)\n",
    "        job = job.json()\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_job(job_id):\n",
    "    new_url = f'{url}/jobs/{job_id}/run'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    payload = {\n",
    "        \"immediate_return\": True # required to set this to True for polling.\n",
    "    }\n",
    "    async with httpx.AsyncClient(timeout=6000) as client:\n",
    "        job = await client.post(new_url, headers=headers, json=payload)\n",
    "        job = job.json()\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_result(result_id):\n",
    "    new_url = f'{url}/results/{result_id}'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    async with httpx.AsyncClient(timeout=60) as client:\n",
    "        job = await client.get(new_url, headers=headers)\n",
    "        job = job.json()\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def poll_result(result_id, interval=3):\n",
    "    while True:\n",
    "        result = await get_result(result_id)\n",
    "        if result['status'] != 'running':\n",
    "            return result\n",
    "        await asyncio.sleep(interval)  # Wait for the specified interval before polling again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_mappings_from_result(result_id, page=1, size=50):\n",
    "    new_url = f'{url}/results/{result_id}/mappings'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    params = {\n",
    "        'page': page,  # Assuming you want to access the second page\n",
    "        'size': size  # Number of records per page\n",
    "    }\n",
    "    async with httpx.AsyncClient(timeout=60) as client:\n",
    "        job = await client.get(new_url, headers=headers, params=params)\n",
    "        job = job.json()\n",
    "    return job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to iterate over all pages of pipelines to get all pipelines\n",
    "async def get_all_pipelines():\n",
    "    new_url = f'{url}/pipelines' \n",
    "    headers = {\"lume-api-key\": api_key} \n",
    "    all_pipelines = []\n",
    "    page = 1\n",
    "    total_pages = None\n",
    "\n",
    "    async with httpx.AsyncClient(timeout=60) as client:\n",
    "        while total_pages is None or page <= total_pages:\n",
    "            response = await client.get(f\"{new_url}?page={page}\", headers=headers)\n",
    "            data = response.json()\n",
    "            all_pipelines.extend(data['items'])\n",
    "            if total_pages is None:\n",
    "                total_items = data['total']\n",
    "                page_size = data['size']\n",
    "                total_pages = (total_items + page_size - 1) // page_size  # Calculate total pages\n",
    "            page += 1\n",
    "\n",
    "    return all_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search(model, params):\n",
    "    new_url = f'{url}/search'\n",
    "    headers = {\"lume-api-key\": api_key}\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"params\": params\n",
    "    }\n",
    "    async with httpx.AsyncClient(timeout=6000) as client:\n",
    "        retPage = await client.post(new_url, headers=headers, json=payload)\n",
    "        retPage = retPage.json()\n",
    "    return retPage['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_pipeline_with_name(pipeline_name):\n",
    "    pipelines = await search('pipeline', {'name': pipeline_name})\n",
    "    if len(pipelines) < 1:\n",
    "        raise ValueError(f\"Pipeline with name {pipeline_name} not found\")\n",
    "    pipeline = pipelines[0]\n",
    "    print(\"Fetched pipeline\", pipeline['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_all_mappings(result_id):\n",
    "    mappings = []\n",
    "    first_page = await get_mappings_from_result(result_id)\n",
    "    mappings.extend(first_page['items'])\n",
    "\n",
    "    total_items = first_page['total']\n",
    "    page_size = first_page['size']\n",
    "    total_pages = total_items // page_size + 1\n",
    "\n",
    "    for page in range(2, total_pages + 1):\n",
    "        new_mappings_page = await get_mappings_from_result(result_id, page=page)\n",
    "        mappings.extend(new_mappings_page['items'])\n",
    "    return mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Context\n",
    "\n",
    "This cookbook assumes a pipeline has already been created, called `ecomm_test`. The existing pipeline is meant to map source ecommerce data to an internal ecommerce data model. The target schema used in the pipeline is in this cookbook's folder, as `target_schema.json`. The cell below loads the target schema. You can view it in detail in taret_schema.json within this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_schema_path = os.path.join(os.getcwd(), 'target_schema.json')\n",
    "with open(target_schema_path) as f:\n",
    "    target_schema = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Let's access our source data and use a Lume pipeline to map it automatically.\n",
    "\n",
    "The source data is in this cookbook's folder, as `source_data.json`. The cell below loads the source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_path = os.path.join(os.getcwd(), 'source_data.json')\n",
    "with open(source_data_path) as f:\n",
    "    source_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use Lume to map this source data automatically, using an existing pipeline. To do so,\n",
    "1. Get the corresponding pipeline for your data.\n",
    "2. Create a job for the pipeline, and provide the source data.\n",
    "3. Run the job\n",
    "4. Get output from the finished job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Get the corresponding pipeline for your data\n",
    "Depending on where your source data arrived (system x, api y, etc), use that knowledge to fetch the corresponding pipeline via the pipeline name, `ecomm_test` in this case. Pipeline names allow you use easily find pipelines, and customers typically use semantic text (e.g. systemA_pipeline_to_X_target) or hashes to discern this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'ecommerce-demo'\n",
    "pipeline = await get_pipeline_with_name(pipeline_name)\n",
    "if pipeline:\n",
    "    print(f\"Found pipeline: {pipeline['name']}\") #printing only certain pipeline properties, for brevity. The pipeline object also stores the target schema.\n",
    "else:\n",
    "    print(\"Pipeline not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Create a job for the pipeline, and provide the source data.\n",
    "Use the id of the returned pipeline to create a job. Also pass in the source data to map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = await create_job(pipeline['id'], source_data)\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Run the job\n",
    "First call run_job, which will return a result immediately. To wait for a job to finish, poll the result endpoint until the status of the job is not `running`. Once done, the result will be `finished`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_result = await run_job(job['id'])\n",
    "result = await poll_result(initial_result['id'])\n",
    "print(f\"Job completed with result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a job run executes to completion, a Result object is returned. The Result provides a few pieces of key information:\n",
    "1. Status: the status of the job. If finished, the job executed with no errors or flags. \n",
    "2. spec: the high-order mapping logic and lookup table of the pipeline used on this job. \n",
    "3. id: the Result id. Use this to access the output mappings of the job run via Get Mappings For Result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Get output from the finished job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A finished job allows you to then access the spec and mapped data. First, let's access the spec via result. The spec indicates:\n",
    "1. Which source properties are used to map to each target property\n",
    "2. The default value is the source property is not present, or if there is no source property indicated.\n",
    "\n",
    "There is a spec for every target property. For simplicity, let's access the spec for the `product.name` target property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = result['spec']\n",
    "product_name_spec = spec['product']['name']\n",
    "product_name_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this mapping is doing a 1:1 extract from the `product.title` source property, and it is defaulting to `null` if the source property does not exist in the record.\n",
    "\n",
    "Now, let's access the mapped data by querying the underlying mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappingsPage = await get_mappings_from_result(result['id'], page=1, size=10)\n",
    "mappings = mappingsPage['items']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the source data was successfully mapped by Lume to your desired target schema, and you have access to the data via `mappings`. For each source record, you can access the corresponding mapped data via the `index` and `mapped_data` properties. `mappings` is a list where each object of mapped data represents a source record.\n",
    "\n",
    "For more detail, we can zoom in to the first record of `mappings`. Each object will have information on:\n",
    "1. `index`: The index of the source record in question\n",
    "2. `source_record`\n",
    "2. `mapped_data`: The final mapped data record\n",
    "3. `message`: either `success` or a json error. If a record is not marked as `success`, it failed a Lume type check against your specified target schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Pipe the output to your end destination\n",
    "Iterate through the mappings to get the final mapped data, and send it to the next step of your workflow. Use the `get_all_mappings` utility function to iterate through all the pages of data, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mappings = await get_all_mappings(result['id'])\n",
    "all_mappings\n",
    "\n",
    "# TODO: send all_mappings to the next step in the pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
